{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Challenge: Upsell Campaign\n",
        "\n",
        "This notebook demonstrates the process for building predictive models to identify customers likely to accept upsell offers.\n",
        "The steps include:\n",
        "- Data loading and preparation\n",
        "- Model implementation with hyperparameter tuning\n",
        " - Evaluation of models using validation metrics\n",
        "- Predictions on the test dataset\n"
      ],
      "metadata": {
        "id": "X55ApUWV0buE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Data loading and preparation\n"
      ],
      "metadata": {
        "id": "xlMaRT5s10xU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load the training and test datasets from CSV files.\n",
        "train_data_path = 'upsell_train_corrected.csv'\n",
        "test_data_path = 'upsell_test_corrected_WITHOUT_TARGET.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_data_path)\n",
        "test_df = pd.read_csv(test_data_path, sep=';')"
      ],
      "metadata": {
        "id": "2SfmMfdnIXif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now handle missing values, encode categorical variables, and standardize numerical features."
      ],
      "metadata": {
        "id": "6jIAoZZqIrlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target in the training set\n",
        "X = train_df.drop(columns=['upsell'])\n",
        "y = train_df['upsell']\n",
        "\n",
        "# Handle missing values\n",
        "X['income'] = X['income'].fillna(X['income'].median())\n",
        "X['engagement_score'] = X['engagement_score'].fillna(X['engagement_score'].median())\n",
        "\n",
        "test_df['income'] = test_df['income'].fillna(X['income'].median())\n",
        "test_df['engagement_score'] = test_df['engagement_score'].fillna(X['engagement_score'].median())\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_columns = ['subscription_type', 'region', 'device_type']\n",
        "encoders = {col: LabelEncoder() for col in categorical_columns}\n",
        "for col in categorical_columns:\n",
        "    X[col] = encoders[col].fit_transform(X[col])\n",
        "    test_df[col] = encoders[col].transform(test_df[col])\n",
        "\n",
        "# Standardize numerical variables\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'income', 'account_age', 'clicks_last_month',\n",
        "                     'promo_clicks', 'engagement_score', 'last_login_days',\n",
        "                     'previous_upsell_attempts', 'average_session_time']\n",
        "\n",
        "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
        "test_df[numerical_columns] = scaler.transform(test_df[numerical_columns])\n",
        "\n",
        "# Split training data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Remove unnecessary columns from test set\n",
        "test_features = test_df.drop(columns=['Id'])"
      ],
      "metadata": {
        "id": "y4-oInY2ImdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation and Hyperparameter Tuning  \n",
        "Each model is trained using the training dataset. Hyperparameters are tuned, and validation metrics such as F1-Score and AUC are calculated to assess model performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "a3Z_E8Da9aEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Capture Rate\n",
        "def calculate_capture_rate(y_true, y_pred_prob):\n",
        "    # Create a DataFrame with true values and predicted probabilities\n",
        "    results = pd.DataFrame({'y_true': y_true, 'y_pred_prob': y_pred_prob})\n",
        "\n",
        "    # Sort by predicted probability (descending order)\n",
        "    results = results.sort_values(by='y_pred_prob', ascending=False)\n",
        "\n",
        "    # Calculate the threshold for the top 10% (0.1 proportion)\n",
        "    top_10_percent = int(len(results) * 0.1)\n",
        "\n",
        "    # Get the top 10% rows\n",
        "    top_10_results = results.head(top_10_percent)\n",
        "\n",
        "    # Calculate the capture rate as the proportion of true positives in the top 10%\n",
        "    capture_rate = top_10_results['y_true'].sum() / top_10_percent\n",
        "\n",
        "    return capture_rate\n",
        "\n",
        "# Initialize a dictionary to store model predictions for the test set\n",
        "model_predictions = {}"
      ],
      "metadata": {
        "id": "kx6DKSLkJOgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Logistic Regression**"
      ],
      "metadata": {
        "id": "BMxXuyvcJUHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logit_model.fit(X_train, y_train)\n",
        "\n",
        "# Validation Metrics\n",
        "logit_val_pred = logit_model.predict(X_val)\n",
        "logit_val_prob = logit_model.predict_proba(X_val)[:, 1]\n",
        "print(\"Logistic Regression Validation Metrics\")\n",
        "print(f\"F1 Score: {f1_score(y_val, logit_val_pred)}\")\n",
        "print(f\"AUC: {roc_auc_score(y_val, logit_val_prob)}\")\n",
        "\n",
        "# Capture Rate for Logistic Regression\n",
        "logit_capture_rate = calculate_capture_rate(y_val, logit_val_prob)\n",
        "print(f\"Logistic Regression Capture Rate: {logit_capture_rate}\")\n",
        "\n",
        "# Test Predictions\n",
        "y_test_prob_logit = logit_model.predict_proba(test_features)[:, 1]\n",
        "y_test_pred_logit = logit_model.predict(test_features)\n",
        "model_predictions['Logistic Regression'] = (y_test_pred_logit, y_test_prob_logit)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEqDNHWqJuBp",
        "outputId": "fa9fcbc2-8dbd-4cbe-cfc9-0ab962637d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Validation Metrics\n",
            "F1 Score: 0.29991980753809144\n",
            "AUC: 0.7311637840317577\n",
            "Logistic Regression Capture Rate: 0.644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**K-Nearest Neighbors**"
      ],
      "metadata": {
        "id": "R5Rx4AEpJUTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier()\n",
        "knn_params = {'n_neighbors': [3, 5, 7]}\n",
        "grid_knn = GridSearchCV(knn_model, knn_params, scoring='f1', cv=5)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "# Best Model\n",
        "best_knn = grid_knn.best_estimator_\n",
        "knn_val_pred = best_knn.predict(X_val)\n",
        "knn_val_prob = best_knn.predict_proba(X_val)[:, 1]\n",
        "print(\"KNN Validation Metrics\")\n",
        "print(f\"F1 Score: {f1_score(y_val, knn_val_pred)}\")\n",
        "print(f\"AUC: {roc_auc_score(y_val, knn_val_prob)}\")\n",
        "\n",
        "# Capture Rate for KNN\n",
        "knn_capture_rate = calculate_capture_rate(y_val, knn_val_prob)\n",
        "print(f\"KNN Capture Rate: {knn_capture_rate}\")\n",
        "\n",
        "# Test Predictions\n",
        "y_test_prob_knn = best_knn.predict_proba(test_features)[:, 1]\n",
        "y_test_pred_knn = best_knn.predict(test_features)\n",
        "model_predictions['KNN'] = (y_test_pred_knn, y_test_prob_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42Zf_C9YJm_J",
        "outputId": "752e10d2-5de5-4b83-b9fa-1a43c1213a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Validation Metrics\n",
            "F1 Score: 0.5453474676089517\n",
            "AUC: 0.7747786499123716\n",
            "KNN Capture Rate: 0.748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree & Random Forest**"
      ],
      "metadata": {
        "id": "Ou_S_vYxJUh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Validation Metrics\n",
        "dt_val_pred = dt_model.predict(X_val)\n",
        "dt_val_prob = dt_model.predict_proba(X_val)[:, 1]\n",
        "print(\"Decision Tree Validation Metrics\")\n",
        "print(f\"F1 Score: {f1_score(y_val, dt_val_pred)}\")\n",
        "print(f\"AUC: {roc_auc_score(y_val, dt_val_prob)}\")\n",
        "\n",
        "# Capture Rate for Decision Tree\n",
        "dt_capture_rate = calculate_capture_rate(y_val, dt_val_prob)\n",
        "print(f\"Decision Tree Capture Rate: {dt_capture_rate}\")\n",
        "\n",
        "# Test Predictions\n",
        "y_test_prob_dt = dt_model.predict_proba(test_features)[:, 1]\n",
        "y_test_pred_dt = dt_model.predict(test_features)\n",
        "model_predictions['Decision Tree'] = (y_test_pred_dt, y_test_prob_dt)\n",
        "\n",
        "#Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Capture Rate for Random Forest\n",
        "rf_capture_rate = calculate_capture_rate(y_val, rf_val_prob)\n",
        "print(f\"Random Forest Capture Rate: {rf_capture_rate}\")\n",
        "\n",
        "# Validation Metrics\n",
        "rf_val_pred = rf_model.predict(X_val)\n",
        "rf_val_prob = rf_model.predict_proba(X_val)[:, 1]\n",
        "print(\"Random Forest Validation Metrics\")\n",
        "print(f\"F1 Score: {f1_score(y_val, rf_val_pred)}\")\n",
        "print(f\"AUC: {roc_auc_score(y_val, rf_val_prob)}\")\n",
        "\n",
        "# Test Predictions\n",
        "y_test_prob_rf = rf_model.predict_proba(test_features)[:, 1]\n",
        "y_test_pred_rf = rf_model.predict(test_features)\n",
        "model_predictions['Random Forest'] = (y_test_pred_rf, y_test_prob_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXnZKSajKLn2",
        "outputId": "d4f7b98e-d0e2-4487-8a5a-69f567eb6d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Validation Metrics\n",
            "F1 Score: 0.6034725480994838\n",
            "AUC: 0.7521996801346964\n",
            "Decision Tree Capture Rate: 0.586\n",
            "Random Forest Capture Rate: 0.95\n",
            "Random Forest Validation Metrics\n",
            "F1 Score: 0.6845878136200717\n",
            "AUC: 0.9207704166298922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Support Vector Machine (SVM)**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rEjFJoLhJUxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(probability=True, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Validation Metrics\n",
        "svm_val_pred = svm_model.predict(X_val)\n",
        "svm_val_prob = svm_model.predict_proba(X_val)[:, 1]\n",
        "print(\"SVM Validation Metrics\")\n",
        "print(f\"F1 Score: {f1_score(y_val, svm_val_pred)}\")\n",
        "print(f\"AUC: {roc_auc_score(y_val, svm_val_prob)}\")\n",
        "\n",
        "# Capture Rate for SVM\n",
        "svm_capture_rate = calculate_capture_rate(y_val, svm_val_prob)\n",
        "print(f\"SVM Capture Rate: {svm_capture_rate}\")\n",
        "\n",
        "# Test Predictions\n",
        "y_test_prob_svm = svm_model.predict_proba(test_features)[:, 1]\n",
        "y_test_pred_svm = svm_model.predict(test_features)\n",
        "model_predictions['SVM'] = (y_test_pred_svm, y_test_prob_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oAqXNY-LFsm",
        "outputId": "aa2d08ab-46f2-4d2b-c44a-fe93a4da23ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Validation Metrics\n",
            "F1 Score: 0.5867549668874172\n",
            "AUC: 0.8987745851595301\n",
            "SVM Capture Rate: 0.936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Artificial Neural Network (ANN)**"
      ],
      "metadata": {
        "id": "grSMqcqAJVPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "ann_model.fit(X_train, y_train)\n",
        "\n",
        "# Validation Metrics\n",
        "ann_val_pred = ann_model.predict(X_val)\n",
        "ann_val_prob = ann_model.predict_proba(X_val)[:, 1]\n",
        "print(\"ANN Validation Metrics\")\n",
        "print(f\"F1 Score: {f1_score(y_val, ann_val_pred)}\")\n",
        "print(f\"AUC: {roc_auc_score(y_val, ann_val_prob)}\")\n",
        "\n",
        "# Calculate Capture Rate for ANN\n",
        "ann_capture_rate = calculate_capture_rate(y_val, ann_val_prob)\n",
        "print(f\"ANN Capture Rate: {ann_capture_rate}\")\n",
        "\n",
        "# Test Predictions\n",
        "y_test_prob_ann = ann_model.predict_proba(test_features)[:, 1]\n",
        "y_test_pred_ann = ann_model.predict(test_features)\n",
        "model_predictions['ANN'] = (y_test_pred_ann, y_test_prob_ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPpJ0ypiLHhv",
        "outputId": "6cf12a6a-6546-4183-8d69-48dd4ad39b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN Validation Metrics\n",
            "F1 Score: 0.7509025270758123\n",
            "AUC: 0.9300503171981428\n",
            "ANN Capture Rate: 0.956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predictions on the test dataset\n",
        "We export predictions for each model to separate sheets in a single Excel file.\n"
      ],
      "metadata": {
        "id": "DJU0_C6oFH69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predictions to Excel\n",
        "output_file = 'Upsell_Predictions.xlsx'\n",
        "with pd.ExcelWriter(output_file) as writer:\n",
        "    for model_name, (pred_class, pred_prob) in model_predictions.items():\n",
        "        results = pd.DataFrame({\n",
        "            'ID': test_df['Id'],\n",
        "            'Predicted Class': pred_class,\n",
        "            'Predicted Probability': pred_prob\n",
        "        })\n",
        "        results.to_excel(writer, sheet_name=model_name, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibBqU76TI_5d",
        "outputId": "4d95a75f-3c6c-4608-8d0b-b2e9ed62b725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to Upsell_Predictions.xlsx\n"
          ]
        }
      ]
    }
  ]
}